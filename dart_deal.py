print("âœ… ì½”ë“œ ì‹œì‘ë¨")  # ë§¨ ìœ„ì— ì¶”ê°€

import os
import warnings
import pandas as pd
import OpenDartReader
from tqdm import tqdm
from datetime import datetime as dt, timedelta
import requests
from bs4 import BeautifulSoup
import re
import time

warnings.filterwarnings('ignore')

# ğŸ“Œ ê²½ë¡œ ì„¤ì •
base_dir = os.path.abspath("ê¸°ë³¸ ê²½ë¡œ ì…ë ¥")
new_project_dir = os.path.join(base_dir, "í´ë” ì…ë ¥")

# âœ… ì €ì¥í•  í´ë” ê²½ë¡œ
new_data_dir = os.path.join(new_project_dir, "ê²°ê³¼ë¬¼ í´ë”ëª… ì…ë ¥")
os.makedirs(new_data_dir, exist_ok=True)  # âœ… í´ë” ì—†ìœ¼ë©´ ìë™ ìƒì„±

print("âœ… Script started...")

# ğŸ“Œ OpenDart API ì„¤ì •
api_key = 'DART API KEY'  # ğŸ”´ ì‹¤ì œ API í‚¤ ì…ë ¥ í•„ìš”
dart = OpenDartReader(api_key)

# ğŸ“Œ KOSPI ê¸°ì—… ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
list_df = pd.read_excel(os.path.join(base_dir, 'data', '02.mktcap_3000.xlsx'), sheet_name='list', index_col=0)

def get_dcm_no(rcp_no):
    """ğŸ“Œ DARTì—ì„œ dcmNo ì°¾ê¸°"""
    main_url = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcp_no}"
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(main_url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')

    script_tag = soup.find("script", string=re.compile("viewDoc"))
    if script_tag:
        match = re.search(r'viewDoc\(".*?",\s*"(\d+)"', script_tag.text)
        if match:
            return match.group(1)
    return None

def get_dart_document_url(rcp_no, dcm_no):
    """ğŸ“Œ DART ë³¸ë¬¸ HTML URL ê°€ì ¸ì˜¤ê¸°"""
    return f"https://dart.fss.or.kr/report/viewer.do?rcpNo={rcp_no}&dcmNo={dcm_no}&dtd=HTML"

def extract_contract_info(rcp_no):
    """ğŸ“Œ DARTì—ì„œ ê³„ì•½ ì •ë³´ ì¶”ì¶œ"""
    dcm_no = get_dcm_no(rcp_no)
    if not dcm_no:
        print(f"âŒ dcmNo not found for rcp_no: {rcp_no}")
        return {"contract_type": "ì¡°íšŒ ì‹¤íŒ¨", "contract_name": "ì¡°íšŒ ì‹¤íŒ¨", "contract_party": "ì¡°íšŒ ì‹¤íŒ¨"}

    doc_url = get_dart_document_url(rcp_no, dcm_no)

    print(f"ğŸ” Fetching contract details from: {doc_url}")
    time.sleep(3)

    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(doc_url, headers=headers)

    # ğŸ”¹ ì¸ì½”ë”© í™•ì¸ ë° ì„¤ì •
    encoding = response.apparent_encoding
    response.encoding = encoding
    print(f"âœ… Detected encoding: {encoding}")

    soup = BeautifulSoup(response.text, 'html.parser')

    contract_info = {
        "contract_type": "",
        "contract_name": "",
        "contract_party": ""
    }

    # ğŸ” ê³µì‹œ ë³¸ë¬¸ì—ì„œ ê³„ì•½ ì •ë³´ ì¶”ì¶œ (iframe ì—†ì´ ì§ì ‘ ì°¾ê¸°)
    for row in soup.find_all("tr"):
        cells = row.find_all(["th", "td"])
        if len(cells) > 1:
            header = cells[0].get_text(strip=True)
            value = cells[1].get_text(strip=True)

            if "íŒë§¤ã†ê³µê¸‰ê³„ì•½ êµ¬ë¶„" in header:
                contract_info["contract_type"] = value
            elif "ì²´ê²°ê³„ì•½ëª…" in header or "ì„¸ë¶€ë‚´ìš©" in header:  # ğŸ”¹ ì²´ê²°ê³„ì•½ëª… ë˜ëŠ” ì„¸ë¶€ë‚´ìš©
                contract_info["contract_name"] = value
            elif "ê³„ì•½ìƒëŒ€" in header:
                contract_info["contract_party"] = value

    if not any(contract_info.values()):  # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°
        print("âŒ ê³„ì•½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. HTML êµ¬ì¡° ë³€ê²½ í™•ì¸ í•„ìš”.")

    return contract_info

def process_disclosures(Dart_df):
    """ğŸ“Œ ê³µì‹œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê°œë³„ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
    for i in tqdm(Dart_df.index):
        try:
            code = i[1:]

            # âœ… ë‹¤íŠ¸ APIì—ì„œ ê¸°ì—…ëª… ê°€ì ¸ì˜¤ê¸°
            company_info = dart.company(code)
            stock_name = company_info['corp_name'] if company_info is not None else "ì¡°íšŒ ì‹¤íŒ¨"

            enddate = dt.today().strftime('%Y-%m-%d')
            startdate = (dt.today() - timedelta(days=3*365)).strftime('%Y-%m-%d')

            result_list = dart.list(code, start=startdate, end=enddate, kind='I', final=False)
            disclosures = result_list[result_list.report_nm.str.contains("ê³µê¸‰ê³„ì•½ì²´ê²°")]

            if disclosures.empty:
                continue  # ğŸ”¹ ê³µì‹œê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ê¸°ì—…ìœ¼ë¡œ

            extracted_reports = []
            for _, result in disclosures.iterrows():
                rcp_no = result['rcept_no']
                contract_info = extract_contract_info(rcp_no)

                # âœ… ì—‘ì…€ ì–‘ì‹ì— ë§ê²Œ ë°ì´í„° ì¶”ê°€
                extracted_reports.append({
                    "ì¢…ëª©ëª…": stock_name,
                    "ëŒ€ë¶„ë¥˜": contract_info["contract_type"],  # âœ… contract_type â†’ ëŒ€ë¶„ë¥˜
                    "ì¤‘ë¶„ë¥˜": "íŒë§¤ì²˜",  # âœ… "íŒë§¤ì²˜"ë¡œ ê³ ì •
                    "ì†Œë¶„ë¥˜": contract_info["contract_name"],  # âœ… contract_name â†’ ì†Œë¶„ë¥˜
                    "ì—°ê´€ê¸°ì—…": contract_info["contract_party"],  # âœ… contract_party â†’ ì—°ê´€ê¸°ì—…
                })

            # âœ… DataFrame ë³€í™˜ ë° ì¤‘ë³µ ì œê±°
            df_result = pd.DataFrame(extracted_reports)

            # âœ… ğŸ”¥ ì¤‘ë³µ ì œê±° (ëŒ€ë¶„ë¥˜, ì†Œë¶„ë¥˜, ì—°ê´€ê¸°ì—…ì´ ë™ì¼í•œ ê²½ìš°)
            df_result.drop_duplicates(subset=["ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì—°ê´€ê¸°ì—…"], keep="first", inplace=True)

            # âœ… ê³µì‹œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ íŒŒì¼ ì €ì¥
            if not df_result.empty:
                excel_output_path = os.path.join(new_data_dir, f"{code}.xlsx")  # âœ… ê¸°ì—…ë³„ ê°œë³„ íŒŒì¼ ì €ì¥
                df_result.to_excel(excel_output_path, index=False, engine="openpyxl")
                print(f"âœ… ì €ì¥ ì™„ë£Œ: {excel_output_path}")

        except Exception as e:
            print(f"âŒ Error processing disclosures for {code}: {e}")
            continue

# âœ… ì‹¤í–‰
process_disclosures(list_df)
print("âœ… Data extraction complete.")
